---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```
# fuzzystring

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![CRAN status](https://www.r-pkg.org/badges/version/fuzzystring)](https://CRAN.R-project.org/package=fuzzystring)
[![R-CMD-check](https://github.com/PaulESantos/fuzzystring/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/PaulESantos/fuzzystring/actions/workflows/R-CMD-check.yaml)
[![Codecov test coverage](https://codecov.io/gh/PaulESantos/fuzzystring/graph/badge.svg)](https://app.codecov.io/gh/PaulESantos/fuzzystring)
<!-- badges: end -->

**fuzzystring** provides fast, flexible fuzzy string joins for data frames using approximate string matching. Built on top of `data.table` and `stringdist`, it's designed for efficiently merging datasets where exact matches aren't possible due to misspellings, inconsistent formatting, or slight variations in text.

## Why fuzzystring?

Real-world data is messy. You might need to:

- Match company names that are spelled slightly differently across datasets
- Join customer records with typos or abbreviations
- Reconcile product catalogs with inconsistent naming
- Link survey responses to predefined categories despite spelling errors
- Merge datasets where identifiers have been transcribed with errors

**fuzzystring** makes these tasks straightforward with:

- **All standard join types**: inner, left, right, full, semi, and anti joins
- **Multiple distance metrics**: Levenshtein, Damerau-Levenshtein, Jaro-Winkler, Soundex, and more
- **High performance**: C++ row binding and `data.table` backend for speed
- **Optional distance column**: Track how close matches are
- **Flexible matching**: Case-insensitive options and customizable distance thresholds

## Installation

``` r
# Development version from GitHub
# Using pak (recommended)
pak::pak("PaulESantos/fuzzystring")

# Or using remotes
remotes::install_github("PaulESantos/fuzzystring")
```

## Quick start

Here's a simple example matching diamond cuts with slight misspellings:

```{r quickstart, eval=FALSE}
library(fuzzystring)

# Your messy data
x <- data.frame(
  name = c("Idea", "Premiom", "Very Good"), 
  id = 1:3
)

# Reference data
y <- data.frame(
  approx_name = c("Ideal", "Premium", "VeryGood"), 
  grp = c("A", "B", "C")
)

# Fuzzy join with max distance of 2 edits
fuzzystring_inner_join(
  x, y,
  by = c(name = "approx_name"),
  max_dist = 2,
  distance_col = "distance"
)
#>      name id approx_name grp distance
#> 1:   Idea  1       Ideal   A        1
#> 2: Premiom  2     Premium   B        2
```

## Key features

### All join types supported

```{r joins, eval=FALSE}
# Inner join - only matching rows
fuzzystring_inner_join(x, y, by = c(name = "approx_name"), max_dist = 2)

# Left join - all rows from x, matching rows from y
fuzzystring_left_join(x, y, by = c(name = "approx_name"), max_dist = 2)

# Right join - all rows from y, matching rows from x
fuzzystring_right_join(x, y, by = c(name = "approx_name"), max_dist = 2)

# Full join - all rows from both tables
fuzzystring_full_join(x, y, by = c(name = "approx_name"), max_dist = 2)

# Semi join - rows from x that have a match in y
fuzzystring_semi_join(x, y, by = c(name = "approx_name"), max_dist = 2)

# Anti join - rows from x that don't have a match in y
fuzzystring_anti_join(x, y, by = c(name = "approx_name"), max_dist = 2)
```

### Multiple distance methods

```{r methods, eval=FALSE}
# Optimal String Alignment (default)
fuzzystring_inner_join(x, y, by = c(name = "approx_name"), method = "osa")

# Damerau-Levenshtein
fuzzystring_inner_join(x, y, by = c(name = "approx_name"), method = "dl")

# Jaro-Winkler (good for names)
fuzzystring_inner_join(x, y, by = c(name = "approx_name"), method = "jw")

# Soundex (phonetic matching)
fuzzystring_inner_join(x, y, by = c(name = "approx_name"), method = "soundex")
```

### Case-insensitive matching

```{r case, eval=FALSE}
fuzzystring_inner_join(
  x, y, 
  by = c(name = "approx_name"),
  ignore_case = TRUE,
  max_dist = 1
)
```

## Extended example: Correcting misspellings

A common use case is matching misspelled words against a dictionary. The package includes a dataset of 4,500+ common misspellings from Wikipedia.

```{r example_setup}
library(tidyverse)
library(fuzzystring)

# Load misspellings dataset
data(misspellings)
misspellings
```

Let's match these against a real dictionary:

```{r dictionary}
# Dictionary from qdapDictionaries package
library(qdapDictionaries)
words <- dplyr::as_tibble(DICTIONARY)
words
```

Sample 1,000 misspellings and find their matches:

```{r sample_and_join}
set.seed(2016)
sub_misspellings <- misspellings %>%
  sample_n(1000)

# Fuzzy join with max distance of 1
joined <- sub_misspellings %>%
  fuzzystring_inner_join(
    words, 
    by = c(misspelling = "word"), 
    max_dist = 1
  )

joined
```

### Analyzing match quality

Check how many misspellings we successfully matched:

```{r accuracy}
# Count unique misspellings matched
joined %>%
  count(misspelling, correct)

# Calculate accuracy
which_correct <- joined %>%
  group_by(misspelling, correct) %>%
  summarize(
    guesses = n(), 
    one_correct = any(correct == word),
    .groups = "drop"
  )

# Percentage getting at least one correct guess
mean(which_correct$one_correct)

# Number with exactly one correct match
sum(which_correct$guesses == 1 & which_correct$one_correct)
```

### Including distance metrics

Add a distance column to see how far apart the matches are:

```{r with_distance}
joined_dists <- sub_misspellings %>%
  fuzzystring_inner_join(
    words, 
    by = c(misspelling = "word"), 
    max_dist = 2,
    distance_col = "distance"
  )

# Find the closest match for each misspelling
closest <- joined_dists %>%
  group_by(misspelling) %>%
  top_n(1, desc(distance)) %>%
  ungroup()

# Distribution of distances
closest %>%
  count(distance)
```

### Using different join types

**Left join** to keep unmatched words:

```{r left_join}
left_joined <- sub_misspellings %>%
  fuzzystring_left_join(
    words, 
    by = c(misspelling = "word"), 
    max_dist = 1
  )

# Show words we couldn't match
left_joined %>%
  filter(is.na(word))
```

**Anti join** to find only unmatched words:

```{r anti_join}
unmatched <- sub_misspellings %>%
  fuzzystring_anti_join(
    words, 
    by = c(misspelling = "word"), 
    max_dist = 1
  )

unmatched
```

## Performance

**fuzzystring** uses a C++ implementation for row binding combined with a `data.table` backend for fast performance on large datasets. The package is optimized for:

- Efficient string distance calculations with prefiltering for Levenshtein-like metrics
- Memory-efficient joins using data.table's reference semantics
- Type-safe column operations preserving factors, dates, and other attributes

## Advanced usage

### Multiple column joins

```{r multicol, eval=FALSE}
# Match on both string similarity and numeric proximity
fuzzystring_inner_join(
  x, y,
  by = c(name = "approx_name", value = "approx_value"),
  match_fun = list(
    name = function(x, y) stringdist::stringdist(x, y) <= 1,
    value = function(x, y) abs(x - y) < 0.5
  )
)
```

### Custom distance functions

```{r custom, eval=FALSE}
# Use custom matching logic
fstring_inner_join(
  x, y,
  by = c(name = "approx_name"),
  match_fun = function(x, y) {
    # Your custom matching logic
    result <- your_distance_function(x, y)
    result <= threshold
  }
)
```

## Related packages

- **[fuzzyjoin](https://github.com/dgrtwo/fuzzyjoin)**: Original fuzzy join implementation (dplyr-based)
- **[stringdist](https://github.com/markvanderloo/stringdist)**: String distance metrics
- **[data.table](https://rdatatable.gitlab.io/data.table/)**: High-performance data manipulation

**fuzzystring** builds on these great packages to provide a fast, data.table-native implementation with C++ optimization.


## Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](.github/CONTRIBUTING.md) for guidelines.

## Code of Conduct

Please note that this project is released with a [Contributor Code of Conduct](.github/CODE_OF_CONDUCT.md). By participating in this project you agree to abide by its terms.

## License

MIT Â© Paul E. Santos Andrade
